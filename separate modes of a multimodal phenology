library(rgbif)
library(lubridate)
library(pastecs)
library(mclust)
library(lme4)

#DOWLOAD EUROPEAN RECORDS FROM GBIF FOR A SPECIES (it takes some time):
b=occ_search(taxonKey=name_backbone(name='Rhingia cmapestris',rank='species', kingdom='animals')$usageKey,decimalLatitude='32,72',
decimalLongitude='-15,36',limit=200000)
tab=as.data.frame(b$data)

#add the julian day column:
tab$julian.day=yday(as.Date(paste(tab$year,tab$month,tab$day,sep="-")))
#remove non precise dated records accumulated on 1st and last day of the year and non located records:
tab=subset(tab,julian.day>1 & julian.day<365 & !is.na(decimalLatitude))

#define the new column
tab$gen=NA

sp=1.3 #smoothing parameter
cutoff=0.07 #cutoff under which we exlude modes (in percentage of the highest mode of the species)

#convert year to factor
tab$year=as.factor(tab$year)

######### FIRST STEP : correct by spatial variables #######

#First mixt model to take in account spatial variables, here we do not take in account Altitude because it is not provided directly by the GBIF, but in our paper we added it to the mix model
model1<- lmer(julian.day~decimalLatitude+decimalLongitude+(1|year), data =tab)

#keep the BIC of this first model without any mode effect
BICvec=BIC(model1)


######### SECOND STEP : DEFINE THE NUMBER OF MODES #######

#sutdy the multimodality in residuals:
tab$resi=residuals(model1)
y=density(tab$resi,kernel="gaussian",from=min(tab$resi),to=max(tab$resi),adjust=sp)$y
y=y[which(y>=cutoff*max(y))]
ae=turnpoints(y)
nbmax=length(which(ae$peaks)) #maximum number of modes (nbmax)

if(nbmax>1){   #follow next steps only if nbmax>1 (phenology is potentially multimodal), either go to the end
for(i in 2:nbmax){
obj=Mclust(tab$resi,G=i,modelNames="E")
tab$cate=as.factor(predict(obj)$classification)
model2 <-lmer(julian.day~decimalLatitude+decimalLongitude+cate+(1|year), data =tab)
BICvec[i]=BIC(model2)
}
#keep the number of mode which minimize the BIC of the mixt model:
nbmode=which.min(BICvec)

if(nbmode>1){   #follow next steps only if nbmode>1 (phenology is multimodal), either go to the end
#classify records using nbmode
obj=Mclust(tab$resi,G=nbmode,modelNames="E")
tab$cate=as.factor(predict(obj)$classification)

#if a mode is non represented in the data, remove it: 
while(length(unique(tab$cate))<nbmode){
nbmode=length(unique(tab$cate))
obj=Mclust(tab$resi,G=nbmode,modelNames="E")
tab$cate=as.factor(predict(obj)$classification)}

######### THIRD STEP : optimize classification #######

#initialize the third step, optimize classification:
modelb <-lmer(julian.day~decimalLatitude+decimalLongitude+cate+(1|year), data =tab)
tab$incerti=obj$uncertainty
tab$resi=residuals(model2)

a2=logLik(modelb)[1]-1
a=logLik(modelb)[1]
nbmode=length(unique(tab$cate))

#start optimization :
while(a>a2){
a2=a
for(i in nbmode:1){
tab$cateb=tab$cate

#change poorly predicted points with negative residuals and transfer them to the previous mode if it is not the first mode:
if(i>1){

#change by set of 1%
tab$cateb=tab$cate
limit2=quantile(tab$resi[which(tab$cate==i)],probs=0.01)
lili=which(tab$resi<limit2 & tab$cate==i)
tab$cateb[lili]=i-1
modelb <- lmer(julian.day~decimalLatitude+decimalLongitude+cateb+(1|year), data =tab)

#if it improves the model, keep the modification:
if(logLik(modelb)[1]>a){
tab$cate[lili]=tab$cateb[lili]
tab$resi=residuals(modelb)
a=logLik(modelb)
}else{
#if previous step does not improve likelihood try to change records by set of 10 records maximum:

tab$cateb=tab$cate
lili=lili[order(abs(tab$resi[lili]),decreasing=T)]
lili=lili[1:min(10,length(lili))]
tab$cateb[lili]=i-1
modelb <- lmer(julian.day~decimalLatitude+decimalLongitude+cateb+(1|year), data =tab)

#if it improves the model, keep the modification
if(logLik(modelb)[1]>a){
tab$cate[lili]=tab$cateb[lili]}
tab$resi=residuals(modelb)
a=logLik(modelb)}
}

#change poorly predicted points with positive residuals and transfer them to the next mode:
if(nbmode>i){
#change by set of 1%
limit2=quantile(tab$resi[which(tab$cate==i)],probs=0.99)
lili=which(tab$resi>limit2 & tab$cate==i)
tab$cateb[lili]=i+1
modelb <- lmer(julian.day~decimalLatitude+decimalLongitude+cateb+(1|year), data =tab)

#if it improves the model, keep the modification:
if(logLik(modelb)[1]>a){
tab$cate[lili]=tab$cateb[lili]
tab$resi=residuals(modelb)
a=logLik(modelb)
}else{
#if previous step does not improve likelihood try to change records by set of 10 records maximum:

tab$cateb=tab$cate
lili=lili[order(abs(tab$resi[lili]),decreasing=T)]
lili=lili[1:min(10,length(lili))]
tab$cateb[lili]=i+1
modelb <- lmer(julian.day~decimalLatitude+decimalLongitude+cateb+(1|year), data =tab)

#if it improves the model, keep the modification:
if(logLik(modelb)[1]>a){
tab$cate[lili]=tab$cateb[lili]
tab$resi=residuals(modelb)
a=logLik(modelb)}}
}
}
}
}
}


#plot the result
library(ggmap)
library(ggplot2)
library(gridExtra)

pl1=ggplot(tab,aes(x=julian.day,fill=as.factor(cate)))+geom_bar()+theme(legend.position="none")
pl2=ggplot(tab,aes(x=decimalLatitude,fill=cate))+geom_bar(position="fill",binwidth=1)+theme(legend.position="none")
pl3=ggplot(tab,aes(x=decimalLongitude,y=decimalLatitude,col=cate))+geom_point()+theme(legend.position="none")
pl4=ggplot(tab,aes(x=decimalLatitude,y=julian.day,col=cate))+geom_point()+theme(legend.position="none")

grid.arrange(pl1,pl2,pl3,pl4,ncol=2)
